This anonymous repo will be ready before Nov.24 (authors need to remove personal information for double blind review).  Readme may be continuously updated to serve as a tutorial.
If it is accepted, the codes will be open-source for the public.

This work was developed with the Eclipse IDE.

To run different configurations:  comment the configurations in parameters.hpp and build&run.


For example:
#define AUTHORLLMSwitchON  
//#define AUTHORLLMSwitchON  

#define NOCSIZEMC8_8X8 
#define LLM_TOKEN_SIZE 1 
#define case1_default
is to run an  attention matrix  in a 8x8 NoC with  8-token (sentence-level) and the configuration is baseline.

The other options are the attention matrix or LeNet
#define AUTHORLLMSwitchON  
//#define AUTHORLLMSwitchON  

The other options are  different NoC sizes
//#define NOCSIZEMC2_4X4      // 2 MCs in 4x4 mesh (base tile pattern)
#define NOCSIZEMC8_8X8      // 8 MCs in 8x8 mesh (2x2 tiles)
//#define NOCSIZEMC32_16X16   // 32 MCs in 16x16 mesh (4x4 tiles)
//#define NOCSIZEMC128_32X32  // 128 MCs in 32x32 mesh (8x8 tiles)


The other options are  different token length, if  #define AUTHORLLMSwitchON   is not commented. 
#define LLM_TOKEN_SIZE 1  // 8tokesn  ~50 seconds on Intel 10700.
//#define LLM_TOKEN_SIZE 2    //128tokens . This takes more than ~20minutes.


The other options are  different configurations.
#define case1_default
//#define case2_samos
//#define case3_affiliatedordering
//#define case4_seperratedordering
//#define case5_COMBO1
//#define case6_COMBO2
//#define case7_FireAdvance
//#define case8_BinarySwitch
//#define case9_MOSAIC1
//#define case10_MOSAIC2
